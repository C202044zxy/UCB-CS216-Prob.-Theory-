## Confidence Intervals

**Problem Statement**

Let $X_1,X_2...X_n$ be i.i.d. $\text{Bernoulli}(q)$ random variables, with mean $\mu = q$ and variance $\sigma^2 = q(1-q)$. We want to estimate the mean $\mu$ and we use the sample mean estimator: 
$$
\overline{X}_n = \frac{X_1+X_2+...+X_n}{n}
$$
Given some confidence level $a\in(0,1)$, we want to construct a confidence interval around $\overline X_n$ such that $\mu$ lies in this interval with probability at least $1-a$. 

**(a)**

Use Chebyshev's inequality in order to show that $\mu$ lies in the interval:
$$
(\overline X_n - \frac{\sigma}{\sqrt n}\frac{1}{\sqrt a}, \overline X_n + \frac{\sigma}{\sqrt n}\frac{1}{\sqrt a})
$$
with the probability at least $1-a$. 

> Comment 1. Chebyshev's inequality.
>
> Let $X$ be a random variable with mean $\mu$ and variance $\sigma^2$. We have: 
> $$
> P(|X-\mu|\geq k\sigma)\leq \frac{\sigma^2}{(k\sigma)^2} = \frac{1}{k^2}
> $$
> *Proof.* Here is the Markov's inequality: 
> $$
> P(X\geq a)\leq\frac{E(X)}{a}
> $$
> Apply the Markov inequality to $(X-\mu)^2$ :
> $$
> P((X-\mu)^2\geq (k\sigma)^2)\leq\frac{E((X-\mu)^2)}{(k\sigma)^2} = \frac{\sigma^2}{(k\sigma)^2} = \frac{1}{k^2}
> $$
> Therefore: 
> $$
> P(|X-\mu|\geq k\sigma)\leq\frac{\sigma^2}{(k\sigma)^2} = \frac{1}{k^2}
> $$

Consider the Chebyshev's inequality for $\overline X_n$: 
$$
P(|\overline X_n-\mu|\geq \frac{\sigma}{\sqrt n}\frac{1}{\sqrt a})\leq \frac{var(\overline X_n)}{\sigma^2}\cdot na
$$
Since $X_1,X_2...X_n$ are i.i.d. random variables: 
$$
var(\overline X_n) = \frac{1}{n^2}var(\sum_{i=1}^{n} X_i) = \frac{1}{n^2}\cdot nvar(X_1) = \frac{\sigma^2}{n}
$$
Then: 
$$
P(|\overline X_n-\mu|\geq \frac{\sigma}{\sqrt n}\frac{1}{\sqrt a})\leq \frac{\frac{\sigma^2}{n}}{\sigma^2}\cdot na =a
$$
Therefore, $\mu$ lies in the interval with the probability at least $1-a$. 

